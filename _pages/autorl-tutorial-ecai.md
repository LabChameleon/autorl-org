---
permalink: /tutorial-ecai/
title: "AutoRL Tutorial 2024"
---

**Slides**: [https://docs.google.com/presentation/d/1MjlUJevqnEgdh9xKA_mpHi9gcNNMIR2LdkZ76MxGVQY/edit?usp=sharing](https://docs.google.com/presentation/d/1MjlUJevqnEgdh9xKA_mpHi9gcNNMIR2LdkZ76MxGVQY/edit?usp=sharing) <BR>
**Colab Notebook links**:
* Practical Session 1: [https://colab.research.google.com/drive/1VjWng8KeGiW1RnsU6FYriaxAOxkBooXc](https://colab.research.google.com/drive/1VjWng8KeGiW1RnsU6FYriaxAOxkBooXc)
* Practical Session 2: [https://colab.research.google.com/drive/1dBTSGHZzvt1mErrt4bedErcdnUiL1Qtn](https://colab.research.google.com/drive/1dBTSGHZzvt1mErrt4bedErcdnUiL1Qtn?usp=sharing)


# Beyond Trial & Error: A Tutorial on Automated Reinforcement Learning

This page serves as an overview of André Biedenkapp and Theresa Eimer's tutorial on AutoRL at ECAI 2024. We will add slides and code examples at a later point.

### Outline
Introduction and algorithmic part on AutoRL (60min):
1. Primer on RL
2. Why Does AutoRL matter?
3. The Choice of ALgorithm matters!
5. Properties of AutoRL Hyperparameter Landscapes
6. Optimizing the Full Pipeline
7. The Role of Networks
8. The role of Environments
Q&A

Practical Session I: Visualizing RL Hyperparameter Landscapes (30min)

Coffee Break (30min)

Practical guidelines and case study of hyperparameters (45min):
1. Examples of successful AutoRL DAC and online approaches
2. Combining AutoRL Approaches
3. Evaluation and Generalization of AutoRL
4. Options for HPO with pros and cons (AC methods, PBT, heuris-
tics, meta-gradients, etc.)
5. Hyperparameters and experimental design
6. Benchmarking (Auto)RL
Q&A

Practical Session II: Tools for HPO in RL (45min)


### Speakers
**Theresa Eimer** is a Ph.D. student at the Leibniz University of Hannover focusing on the intersection of AutoML and Reinforcement Learning. Her goal is to make Reinforcement Learning work out of the box through better generalization and automatic configuration.

**André Biedenkapp** is a Postdoctoral Fellow at the University of Freiburg focusing on dynamic configuration with and for deep reinforcement learning.
With his work, he aims to democratize deep reinforcement learning.
